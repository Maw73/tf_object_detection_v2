{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8387d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs clone https://github.com/Maw73/tf_object_detection_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e2195",
   "metadata": {},
   "source": [
    "# 1. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7106a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.22.3-cp38-cp38-win_amd64.whl (14.7 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.22.3 opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python\n",
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f628f29",
   "metadata": {},
   "source": [
    "# Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "VALID_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'valid')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3eef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM_MODEL_NAME = 'faster_rcnn_resnet' \n",
    "CUSTOM_MODEL_NAME = 'ssd_mobilenet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
    "# PRETRAINED_MODEL_NAME = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
    "# PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43656f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c91647",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a365a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ced7a7",
   "metadata": {},
   "source": [
    "# Uncompressing archive.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the \"tarfile\" module\n",
    "import tarfile\n",
    "  \n",
    "# open file\n",
    "file = tarfile.open('Tensorflow/workspace/images/archive.tar.gz')\n",
    "  \n",
    "# extracting file\n",
    "file.extractall('Tensorflow/workspace/images')\n",
    "  \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4db262",
   "metadata": {},
   "source": [
    "# Downloading the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87320a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a6983",
   "metadata": {},
   "source": [
    "# 3. Installing Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the \"tarfile\" module\n",
    "from zipfile import ZipFile as zp\n",
    "with zp('Tensorflow/protoc/protoc-3.15.6-win64.zip', 'r') as zipObj:\n",
    "  zipObj.extractall(path='Tensorflow/protoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . \n",
    "# if os.name=='nt':\n",
    "# url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "# wget.download(url)\n",
    "# !mv protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "# !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "# !cd {paths['PROTOC_PATH']} \n",
    "# os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "# !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py setup.py && python setup.py build && python setup.py install\n",
    "# !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37bb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall pyparsing -y\n",
    "!pip install pyparsing==2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea224b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc420caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344de17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641cde5",
   "metadata": {},
   "source": [
    "# 4. Verification script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b57fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing was already made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef41dac",
   "metadata": {},
   "source": [
    "# Generating tf-records "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c2988",
   "metadata": {},
   "source": [
    "# Training tf-records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97336074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating tf-records for training dataset\n",
    "train_csv_path = 'Tensorflow/train.csv'\n",
    "train_tfr_path = 'Tensorflow/workspace/annotations/train.records'\n",
    "train_img_path = 'Tensorflow/workspace/images/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6adad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: annotation.txt should be in this format:\n",
    "filename;class;xmin;ymin;xmax;ymax\n",
    "\n",
    "Usage:\n",
    "python3 new_annotations2tfrecords-converter.py \\\n",
    "--csv_input=/media/pchat/Data/datasets/SKU/no_scan_training/training_images/TF_RECORD_annotation.txt \\\n",
    "--output_path=/media/pchat/Data/Documents/Code/tf2/tf_records/no_scan_sku/tf-experiment-training.record \\\n",
    "--image_dir=/media/pchat/Data/datasets/SKU/no_scan_training/training_images/\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "flags = tf.compat.v1.flags\n",
    "flags.DEFINE_string('csv_input1', train_csv_path, 'Path to the CSV input')\n",
    "flags.DEFINE_string('output_path1', train_tfr_path, 'Path to output TFRecord')\n",
    "flags.DEFINE_string('image_dir1', train_img_path, 'Path to images')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "# TO-DO replace this with label map\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'background':\n",
    "        return 0\n",
    "    if row_label == 'car':\n",
    "        return 1\n",
    "    if row_label == 'pedestrian':\n",
    "        return 2\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, \"{}\".format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    \n",
    "    writer = tf.io.TFRecordWriter(FLAGS.output_path1)\n",
    "\n",
    "    \n",
    "    path = os.path.join(FLAGS.image_dir1)\n",
    "\n",
    "    \n",
    "    examples = pd.read_csv(FLAGS.csv_input1, sep=\";\")\n",
    "\n",
    "    \n",
    "    grouped = split(examples, 'filename')\n",
    "    \n",
    "    #print(grouped)\n",
    "    for group in grouped:\n",
    "        \n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path1 = os.path.join(os.getcwd(), FLAGS.output_path1)\n",
    "    print('Successfully created the TFRecords: {}'.format(output_path1))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #tf.app.run()\n",
    "    tf.compat.v1.app.run()\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ceb31",
   "metadata": {},
   "source": [
    "# Valid tf-records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating tf-records for validation dataset\n",
    "valid_csv_path = 'Tensorflow/valid.csv'\n",
    "valid_tfr_path = 'Tensorflow/workspace/annotations/valid.records'\n",
    "valid_img_path = 'Tensorflow/workspace/images/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE: annotation.txt should be in this format:\n",
    "filename;class;xmin;ymin;xmax;ymax\n",
    "\n",
    "Usage:\n",
    "python3 new_annotations2tfrecords-converter.py \\\n",
    "--csv_input=/media/pchat/Data/datasets/SKU/no_scan_training/training_images/TF_RECORD_annotation.txt \\\n",
    "--output_path=/media/pchat/Data/Documents/Code/tf2/tf_records/no_scan_sku/tf-experiment-training.record \\\n",
    "--image_dir=/media/pchat/Data/datasets/SKU/no_scan_training/training_images/\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict\n",
    "\n",
    "flags = tf.compat.v1.flags\n",
    "flags.DEFINE_string('csv_input2', valid_csv_path, 'Path to the CSV input')\n",
    "flags.DEFINE_string('output_path2', valid_tfr_path, 'Path to output TFRecord')\n",
    "flags.DEFINE_string('image_dir2', valid_img_path, 'Path to images')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "# TO-DO replace this with label map\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'background':\n",
    "        return 0\n",
    "    if row_label == 'car':\n",
    "        return 1\n",
    "    if row_label == 'pedestrian':\n",
    "        return 2\n",
    "    else:\n",
    "        None\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, \"{}\".format(group.filename)), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'] / width)\n",
    "        xmaxs.append(row['xmax'] / width)\n",
    "        ymins.append(row['ymin'] / height)\n",
    "        ymaxs.append(row['ymax'] / height)\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(class_text_to_int(row['class']))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    \n",
    "    writer = tf.io.TFRecordWriter(FLAGS.output_path2)\n",
    "\n",
    "    \n",
    "    path = os.path.join(FLAGS.image_dir2)\n",
    "\n",
    "    \n",
    "    examples = pd.read_csv(FLAGS.csv_input2, sep=\";\")\n",
    "\n",
    "    \n",
    "    grouped = split(examples, 'filename')\n",
    "    \n",
    "    #print(grouped)\n",
    "    for group in grouped:\n",
    "        \n",
    "        tf_example = create_tf_example(group, path)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    output_path2 = os.path.join(os.getcwd(), FLAGS.output_path2)\n",
    "    print('Successfully created the TFRecords: {}'.format(output_path2))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #tf.app.run()\n",
    "    tf.compat.v1.app.run()\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421432c",
   "metadata": {},
   "source": [
    "# 6. Faster RCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d2c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will chose Faster RCNN resnet50 from tensorflow model zoo which has\n",
    "# a speed of 53 ms and a mAP OF 29.3 (on COCO dataset)\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc664db",
   "metadata": {},
   "source": [
    "# Copy model config to training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da29607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb04510",
   "metadata": {},
   "source": [
    "# Updating config for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e302df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'car', 'id':1}, {'name':'pedestrian', 'id':2}]\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.records')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'valid.records')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb05ab",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f667695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a train folder in our model directory with a file which can be opened with tensorboard\n",
    "# run inside that folder the following command: tensorboard --logdir=.\n",
    "# go to the printed URL: localhost...\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391460e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328192ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa323650",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a eval folder in our model directory with a file which can be opened with tensorboard\n",
    "# run inside that folder the following command: tensorboard --logdir=.\n",
    "# go to the printed URL: localhost...\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a77b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates our performance matrix for the model generated in the folder \n",
    "# Prints average precision for a certain IoU\n",
    "# Prints loss matrices\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fb698",
   "metadata": {},
   "source": [
    "# Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b92d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uploads our latest checkpoint (the most trained model - on more steps) and we can further use it for detection and test\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
