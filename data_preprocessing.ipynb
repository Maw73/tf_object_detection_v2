{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48019610",
   "metadata": {},
   "source": [
    "# Data preprocessing of updated Udacity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At a first look, the dataset contains 22241 images from which we have the follwing classes \n",
    "# with their corresponding number of instances (appearances within images):\n",
    "# car - 127900\n",
    "# truck - 7194\n",
    "# pedestrian - 21491\n",
    "# trafficLight-Red - 13673\n",
    "# trafficLight-RedLeft - 3482\n",
    "# trafficLight-Yellow - 541\n",
    "# trafficLight-YellowLeft - 28\n",
    "# trafficLight-Green - 10838\n",
    "# trafficLight - 5101\n",
    "# biker - 3704\n",
    "# For creating a balanced dataset we dropped the labels for biker and truck as they were very little compared to the\n",
    "# other classes and merge the classes containg trafficLights\n",
    "# We obtained the following classes with their corresponding instances:\n",
    "# car - 127900\n",
    "# pedestrian - 21491\n",
    "# trafficLight - 34277\n",
    "# Note: around 3000 images from the total were found to be background images (with no classes in th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013285af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\andre\\\\Desktop\\\\Object detection project\\\\TFODCourse')\n",
    "os.chdir('Tensorflow\\\\workspace\\\\export')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d99b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the already created .json file back into a dictionary in order to see which images contain pedestrians/trafficLights and cars\n",
    "# and delete the rest of the images, for balancing the labels\n",
    "# importing the module\n",
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "with open('_dictionary.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    " \n",
    "    # Print the type of data variable\n",
    "    print(\"Type:\", type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890cbd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the dictionary and creating another one where only the the labels for traffic light appear\n",
    "trafficLights_filename = []\n",
    "count_trafficLights = 0\n",
    "for filename in data.keys():\n",
    "    for label in data.get(filename):\n",
    "        if label == \"trafficLight\":\n",
    "            count_trafficLights += 1\n",
    "            trafficLights_filename.append(filename)\n",
    "# trafficLight could have appeared multiple times as a value in the same key, so we have to make a list with unique filenames\n",
    "trafficLights_filename = list(set(trafficLights_filename))\n",
    "# 5101 labels for trafficLight in 3175 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the dictionary and creating another one where only the the labels for pedestrian appear\n",
    "pedestrian_filename = []\n",
    "count_pedestrians = 0\n",
    "for filename in data.keys():\n",
    "    for label in data.get(filename):\n",
    "        if label == \"pedestrian\":\n",
    "            count_pedestrians += 1\n",
    "            pedestrian_filename.append(filename)\n",
    "# pedestrian could have appeared multiple times as a value in the same key, so we have to make a list with unique filenames\n",
    "pedestrian_filename = list(set(pedestrian_filename))\n",
    "# 21491 labels for trafficLight in 7030 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8347f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times the label for cars appear where trafficLight appears\n",
    "count_cars_light = 0\n",
    "for filename in trafficLights_filename:\n",
    "    for label in data.get(filename):\n",
    "        if label == \"car\":\n",
    "            count_cars_light += 1\n",
    "# 16743 cars and 5101 trafficLights in 3175 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d07f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times the label for cars appear where pedestrian appears\n",
    "count_cars_pedestrians = 0\n",
    "for filename in pedestrian_filename:\n",
    "    for label in data.get(filename):\n",
    "        if label == \"car\":\n",
    "            count_cars_pedestrians += 1\n",
    "# 34934 cars and 21491 pedestrians in 7030 images\n",
    "# 56425 rows + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c422e",
   "metadata": {},
   "source": [
    "# Wrong conclusion. We need to take another look on the trafficLight labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "# we will use the second part of the dataset for cars and pedestrian\n",
    "# pedestrian_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the training images with cars and pedestrian to another folder\n",
    "for file in pedestrian_filename:\n",
    "    shutil.move(file, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4daefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a separate .csv file for the new training images\n",
    "old_csv = pd.read_csv('_annotations.csv')\n",
    "# print(type(new_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227c3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening an empty .csv and writing only the images that are needed\n",
    "new_csv = pd.read_csv('out.csv')\n",
    "# df1 = df1.append(new_csv.iloc[2], ignore_index = True)\n",
    "for index, filename in enumerate(old_csv[\"filename\"]):\n",
    "    for name in pedestrian_filename:\n",
    "        if filename == name:\n",
    "            new_csv = new_csv.append(old_csv.iloc[index], ignore_index = True)\n",
    "new_csv.to_csv('new_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bfbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "train_labels = pd.read_csv('_annot.csv')\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35110968",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "#add axes to the image\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "# read and plot the image\n",
    "img_name = '1478020385196089931_jpg.rf.8fa4276fef7ddbc3af2e570ee6d0d818.jpg'\n",
    "image = plt.imread(img_name)\n",
    "plt.imshow(image)\n",
    "\n",
    "# iterating over the image for different objects\n",
    "for _,row in train_labels[train_labels.filename == img_name].iterrows():\n",
    "    xmin = row.xmin\n",
    "    xmax = row.xmax\n",
    "    ymin = row.ymin\n",
    "    ymax = row.ymax\n",
    "    \n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "    \n",
    "    # assign different color to different classes of objects\n",
    "    if row[3] == 'car':\n",
    "        edgecolor = 'r'\n",
    "        ax.annotate('1', xy=(xmax-40,ymin+20))\n",
    "    elif row[3] == 'pedestrian':\n",
    "        edgecolor = 'b'\n",
    "        ax.annotate('2', xy=(xmax-40,ymin+20))\n",
    "        \n",
    "    # add bounding boxes to the image\n",
    "    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')\n",
    "    \n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to test and validation and generate valid.csv and train.csv\n",
    "os.chdir('C:\\\\Users\\\\andre\\\\Desktop\\\\Object detection project\\\\TFODCourse')\n",
    "os.chdir('Tensorflow\\\\workspace\\\\export\\\\train')\n",
    "no_img_id = 7030\n",
    "for c in random.sample(glob.glob('14*'), round(no_img_id*0.1)):\n",
    "    shutil.move(c, 'valid')\n",
    "for c in random.sample(glob.glob('14*'), round(no_img_id*0.1)):\n",
    "    shutil.move(c, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb70275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of filenames from a certain directory\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ab6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the names of files from the train directory and savin them in a list\n",
    "dirName = 'valid';\n",
    "# Get the list of all files in directory tree at given path\n",
    "listOfFiles_valid = getListOfFiles(dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5638fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the list of validation in a .csv file\n",
    "df_valid = pd.DataFrame(listOfFiles_valid) \n",
    "# saving the dataframe \n",
    "df_valid.to_csv('valid.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the names of files from the train directory and savin them in a list\n",
    "dirName = 'test';\n",
    "# Get the list of all files in directory tree at given path\n",
    "listOfFiles_test = getListOfFiles(dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14acc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the list of test in a .csv file\n",
    "df_test = pd.DataFrame(listOfFiles_test) \n",
    "# saving the dataframe \n",
    "df_test.to_csv('test.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
